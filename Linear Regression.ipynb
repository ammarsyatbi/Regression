{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collectData():\n",
    "    data = pd.read_csv('./crypto.csv')\n",
    "    x1 = data['Open'].values\n",
    "    x2 = data['High'].values\n",
    "    data = np.array(list(zip(x1,x2)))\n",
    "    #print (data.head())\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $$Error_{(m,b)} = \\frac{1}{N}\\sum_{i=1}^{N} (y_i - (mx_i + b))^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why square?\n",
    "\n",
    "<i>to get a positive value , magnitude </i>\n",
    "\n",
    "\n",
    "* yi = the actual y/output/target\n",
    "* mxi+b = the calcuated y/output\n",
    "* yi - (mxi+b) = the error \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_points_error(b, m, points):\n",
    "    totalError = 0\n",
    "    \n",
    "    for i in range(0 , len(points)):\n",
    "        x = points[i,0]\n",
    "        y = points[i,1]\n",
    "        #calculate Error\n",
    "        totalError += (y - (m*x + b)) **2\n",
    "        \n",
    "           #calculate its average\n",
    "    return totalError /float(len(points))\n",
    "        \n",
    "def gradient_descent_runner(points, starting_b, starting_m, lr, num_iterations):\n",
    "    b = starting_b\n",
    "    m = starting_m\n",
    "    \n",
    "    #gradient descent\n",
    "    for i in range(num_iterations):\n",
    "        #update b and m withe the new more accurate b and m by performing\n",
    "        #this gradient descent\n",
    "        b, m = step_gradient(b, m, np.array(points), lr)\n",
    "    return [b, m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Derivatives\n",
    "\n",
    "$$\\frac{\\partial}{\\partial m} = \\frac{2}{N}\\sum_{i=1}^{N} -x_i(y_i - (mx_i + b))$$\n",
    "$$\\frac{\\partial}{\\partial b} = \\frac{2}{N}\\sum_{i=1}^{N} (y_i - (mx_i + b))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def step_gradient(b_current, m_current, points, lr):\n",
    "    #starting points\n",
    "    b_gradient = 0\n",
    "    m_gradient = 0\n",
    "    \n",
    "    N = float(len(points))\n",
    "    for i in range(0, len(points)):\n",
    "        x = points[i, 0]\n",
    "        y = points[i, 1]\n",
    "        \n",
    "        #direction with respect to b and m | magnitude ?\n",
    "        #computing partial derivatives of our error function\n",
    "        b_gradient += -(2/N) * (y - ((m_current * x) + b_current))\n",
    "        m_gradient += (2/N) * x * (y - ((m_current * x) + b_current))\n",
    "        \n",
    "    #update our b and m values using this partial derivaties\n",
    "    new_b = b_current - (lr * b_gradient)\n",
    "    new_m = m_current - (lr * m_gradient)\n",
    "    return [new_b, new_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run():\n",
    "    #1: collect data\n",
    "    points = collectData()\n",
    "    \n",
    "    #2: parameter settings\n",
    "    lr = 0.0001\n",
    "    #y = mx + b (m = slope/gradient | b = y-intercept)\n",
    "    init_b = 0\n",
    "    init_m = 0\n",
    "    num_iterations = 1000\n",
    "    \n",
    "    #3: model training\n",
    "    print (\"starting gradient descent at b = {0}, m = {1}, error = {2}\".format(init_b, init_m, compute_points_error(init_b, init_m, points)))\n",
    "    [b, m] = gradient_descent_runner(points, init_b, init_m, lr, num_iterations)    \n",
    "    print \"Running..........\"\n",
    "    print (\"ending point at b = {1}, m = {2}, error = {3}\".format(num_iterations, b, m, compute_points_error(b, m, points)))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting gradient descent at b = 0, m = 0, error = 130549813.95278472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JIN\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:14: RuntimeWarning: overflow encountered in double_scalars\n",
      "C:\\Users\\JIN\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:13: RuntimeWarning: invalid value encountered in double_scalars\n",
      "C:\\Users\\JIN\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:14: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-bc6ee88a277f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-bde018422e32>\u001b[0m in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[1;31m#3: model training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"starting gradient descent at b = {0}, m = {1}, error = {2}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_points_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_descent_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_m\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_iterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"ending point at b = {1}, m = {2}, error = {3}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_points_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-79edfc9cc254>\u001b[0m in \u001b[0;36mgradient_descent_runner\u001b[0;34m(points, starting_b, starting_m, lr, num_iterations)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[1;31m#update b and m withe the new more accurate b and m by performing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[1;31m#this gradient descent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-164ba60de330>\u001b[0m in \u001b[0;36mstep_gradient\u001b[0;34m(b_current, m_current, points, lr)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[1;31m#computing partial derivatives of our error function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mb_gradient\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_current\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_current\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mm_gradient\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm_current\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb_current\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[1;31m#update our b and m values using this partial derivaties\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
